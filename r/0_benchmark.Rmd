---
title: "Benchmark"
date: "Étape 1"
output:
  rmdformats::readthedown:
    highlight: kate
---

Le benchmark servira de seuil objectif à dépasser avec le traitement statistique de la base de données. On se servira d'un XGBM et d'un LGBM. Ce benchmark servira également à identifier les variables importantes (selon la métrique du `Gain`). La métrique qu'on souhaite optimiser est celle du `coefficient normalisé de Gini`.

Le coefficient de Gini est tel que :
$$ \text{Gini} \in \left[ 0, \frac{1 - \text{frac_pos}}{2} \right]$$
Plutôt que d'avoir une borne supérieure variable, on peut normaliser ce coefficient de façon à ce que :
$$ \text{Normalized Gini} \in [0, 1]$$

Le coefficient de Gini est lié à l'aire sous la courbe ROC (AUC). Ainsi, chercher à optimiser le coefficient de Gini (normalisé ou non) revient à optimiser l'AUC.



```{r knitr_init, echo=FALSE, cache=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(echo    = TRUE,
               cache   = FALSE,
               prompt  = FALSE,
               tidy    = FALSE,
               comment = NA)
opts_knit$set(width = 75)
```

# Importation des packages et fonctions externes

Afin de faciliter l'accès aux définitions de fonctions et aux appels de packages, chaque fonction est programmée dans un fichier R séparé et l'ensemble de ces fichiers sont exécutés à travers le fichier `0_packages.R`.

```{r, message=F, warning=F}
source("./0_packages.R")
select = dplyr::select
```

# Importation des données brutes

```{r, warning=F, message=F}
df_train = fread(file = "./../data/Base_train.csv") %>% as.data.frame()
df_test  = fread(file = "./../data/Base_test.csv")  %>% as.data.frame()
```

# Préparation des bases pour la modélisation

* XGBM a besoin d'être alimenté par un df des régresseurs (`train_X`) et d'un vecteur de réponses en facteurs (`train_Y`). Les labels à prédire ne doivent pas commencer par un chiffre (pour des soucis de restrictions de noms de colonnes). On recode `0` par `no` et `1` par `yes`.
* LGBM a besoin d'être alimenté par un objet de type `lgb.Dataset` contenant les régresseurs et les réponses (`train_XY_lgb`). Les régresseurs comme les réponses doivent être en format numérique, la fonction `lgb.prepare` s'occupe de la conversion.
* Le calcul du coefficient de Gini normalisé doit se faire avec des valeurs numériques, d'où `train_Y_num` et `test_Y_num`.
* Les df `train_id` et `test_id` conservent les identifiants au cas où.
* Une phase de gestion de mémoire termine la préparation des données pour éviter la saturation de la mémoire vive pendant le tuning des modèles.

```{r}
# Préparation des données pour le XGBM
train_id        = df_train %>% select(id)
train_X         = df_train %>% select(-target, -id)
train_Y         = factor(df_train$target)
levels(train_Y) = c("no", "yes")
train_Y_num     = df_train$target # servira à calculer le coefficient de Gini

test_id         = df_test %>% select(id)
test_X          = df_test %>% select(-target, -id)
test_Y          = factor(df_test$target)
levels(test_Y)  = c("no", "yes")
test_Y_num      = df_test$target # servira à calculer le coefficient de Gini

# Préparation des données pour le LGBM
train_X_lgb  = as.matrix(lgb.prepare(train_X))
train_Y_lgb  = as.matrix(lgb.prepare(df_train %>% select(target)))

test_X_lgb   = as.matrix(lgb.prepare(test_X))
test_Y_lgb   = as.matrix(lgb.prepare(df_test %>% select(target)))

train_XY_lgb = lgb.Dataset(train_X_lgb, label = train_Y_lgb)

# Gestion mémoire -- suppression des bases initiales puis garbage collection.
rm(df_train)
rm(df_test)
gc()
```

# Benchmark 1 - XGBM

## Aperçu

Quels paramètres sont à régler pour optimiser le modèle ?

```{r}
modelLookup("xgbTree")
```

## Validation croisée

La validation passe par un 5-folds cross validation. Pas plus, pas moins pour des raisons de mémoire disponible et de temps de calcul.

```{r}
tune_control <- trainControl(
  method          = "cv",        # validation method
  number          = 5,           # number of CV folds
  summaryFunction = giniSummary, # summary for evaluation
  classProbs      = T,           # compute probabilities
  savePredictions = T,           # keep predictions in object
  verboseIter     = T            # enable verbose
)

tune_grid = expand.grid(
  nrounds          = seq(50, 300, 50), # number of boosting iterations
  eta              = c(0.05, 0.1),     # shrinkage rate
  max_depth        = c(4, 5, 6),       # max tree depth
  gamma            = 0,                # minimum loss reduction
  colsample_bytree = 0.7,              # subsample ratio of columns
  min_child_weight = 0,                # minimum sum of instance weight
  subsample        = 0.8               # subsample percentage
)
```

La métrique objective est le coefficient normalisé de Gini.

```{r, eval = F}
set.seed(1234)
registerDoMC(cores = 4)
benchmark_xgbtree_model = train(
  x         = train_X,          # training data
  y         = train_Y,          # training labels
  metric    = "NormalizedGini", # objective function
  trControl = tune_control,     # validation tuning
  tuneGrid  = tune_grid,        # hyperparameters tuning
  method    = "xgbTree"         # algorithm used
)
registerDoMC(cores = 1)
```

Les résultats du cross validation sont enregistrés pour éviter de devoir le refaire.

```{r}
# save(benchmark_xgbtree_model, file = "./../data/benchmark_xgbtree_model.RData")
load("./../data/benchmark_xgbtree_model.RData")
```

## Résultats du grid search

```{r}
ggplot(benchmark_xgbtree_model)
```

On note qu'il aurait été intéressant d'élargir le grid search au delà de 300 itérations. Pour une profondeur maximale de 4 et un learning rate de 0.05, la performance en validation est en phase ascendante selon le nombre d'itérations.

## Variable importance

L'importance des variables est donnée par le Gain.

```{r}
fun_imp_ggplot_split_boosting(benchmark_xgbtree_model$finalModel, "Gain")
```

## Prédictions et évaluation

Bien qu'il s'agisse d'un benchmark pour mesurer la performance en cross validation, il est toujours intéressant de garder un oeil sur la performance sur la base d'apprentissage entière et sur la base de test.

```{r}
benchmark_xgbtree_train_preds      = predict(benchmark_xgbtree_model, train_X, type = "prob")
benchmark_xgbtree_test_preds       = predict(benchmark_xgbtree_model, test_X, type = "prob")
benchmark_xgbtree_train_ngini      = normalizedGini(train_Y_num, benchmark_xgbtree_train_preds[,"yes"])
benchmark_xgbtree_test_ngini       = normalizedGini(test_Y_num, benchmark_xgbtree_test_preds[,"yes"])
# on récupère le meilleur Gini du CV directement dans l'objet caret
benchmark_xgbtree_valid_ngini      = max(benchmark_xgbtree_model$results$NormalizedGini)
# Print des résultats
c("Normalized Gini Coeff. (Train)"      = benchmark_xgbtree_train_ngini,
  "Normalized Gini Coeff. (Valid 5fCV)" = benchmark_xgbtree_valid_ngini,
  "Normalized Gini Coeff. (Test)"       = benchmark_xgbtree_test_ngini)
```





# Benchmark 2 - LGBM

On fait de même avec un LGBM.

## Validation croisée

```{r}
params_lgb = list(
  objective        = "binary", # type of exercise
  metric           = "auc",    # metric to be evaluated
  learning_rate    = 0.01,     # shrinkage rate
  max_depth        = 10,       # max depth for tree model (used to deal with over-fitting when data is small)
  num_leaves       = 20,       # max number of leaves (nodes) in one tree
  is_unbalance     = T,        # is data unbalanced
  min_data_in_leaf = 10,       # min number of data in one leaf (used to deal with over-fitting)
  feature_fraction = 0.8,      # randomly select part of the features on each iteration
  bagging_fraction = 0.8,      # randomly select part of the data without resampling
  bagging_freq     = 5,        # if != 0, enables bagging, performs bagging at every k iteration
  num_threads      = 6         # number of cpu cores (not threads) to use
)
```

```{r, eval = F}
set.seed(1234)
benchmark_lgb_cv = lgb.cv(
  params                = params_lgb,         # hyperparameters
  data                  = train_XY_lgb,       # lgb.Dataset object for training
  eval                  = lgb.normalizedgini, # custom metric, additionnal to first metric
  nrounds               = 1000,               # maximum iterations
  early_stopping_rounds = 50,                 # if metric evaluation doesn't increase
  verbose               = 1,                  # enable verbose
  eval_freq             = 50,                 # verbose every n iterations
  nfold                 = 5                   # k-folds CV
)
```

## Modèle final

Le package lightgbm ne conserve pas le modèle optimisé, on récupère les paramètres et l'itération optimale pour reconstruire le modèle optimisé.

```{r, eval = F}
benchmark_lgb_model <- lgb.train(
  params    = params_lgb,                 # hyperparameters
  data      = train_XY_lgb,               # lgb.Dataset object for training
  valids    = list(train = train_XY_lgb), # lgb.Dataset object for validation
  eval      = lgb.normalizedgini,         # custom metric, additionnal to first metric
  nrounds   = benchmark_lgb_cv$best_iter, # nrounds from CV
  verbose   = 1,                          # enable verbose
  eval_freq = 50                          # verbose every n iterations
)
```

Note technique : La construction du modèle LGBM s'est faite avec du calcul parallèle et pour des raisons inconnues, la sauvegarde traditionnelle par `save()` ne permet pas de réutiliser le modèle. En effet, en utilisant un `load()`, quelconque appel au modèle engendre une erreur (référence : segfault). Le package a prévu des fonctions de sauvegarde du modèle dédiées : `lgb.save()` (couplé avec `lgb.load()`).

```{r}
# lgb.save(benchmark_lgb_model, filename = "./../data/benchmark_lgb_model.txt")
# save(benchmark_lgb_cv, file = "./../data/benchmark_lgb_cv.RData")
load("./../data/benchmark_lgb_cv.RData")
benchmark_lgb_model = lgb.load("./../data/benchmark_lgb_model.txt")
```

## Variable importance

```{r}
fun_imp_ggplot_split_boosting(benchmark_lgb_model, "Gain")
```

## Prédictions et évaluation

```{r}
benchmark_lgb_train_preds            = predict(benchmark_lgb_model, train_X_lgb)
benchmark_lgb_test_preds             = predict(benchmark_lgb_model, test_X_lgb)
benchmark_lgb_train_ngini            = normalizedGini(train_Y_num, benchmark_lgb_train_preds)
benchmark_lgb_test_ngini             = normalizedGini(test_Y_num, benchmark_lgb_test_preds)
benchmark_lgb_valid_ngini            = max(unlist(benchmark_lgb_cv[["record_evals"]][["valid"]][["Norm-gini"]][["eval"]]))
c("Normalized Gini Coeff. (Train)"      = benchmark_lgb_train_ngini,
  "Normalized Gini Coeff. (Valid 5fCV)" = benchmark_lgb_valid_ngini,
  "Normalized Gini Coeff. (Test)"       = benchmark_lgb_test_ngini)
```

# Conclusion

```{r}
print("XGBTREE/BENCHMARK")
c("Normalized Gini Coeff. (Train)"      = benchmark_xgbtree_train_ngini,
  "Normalized Gini Coeff. (Valid 5fCV)" = benchmark_xgbtree_valid_ngini,
  "Normalized Gini Coeff. (Test)"       = benchmark_xgbtree_test_ngini)

print("LGBM/BENCHMARK")
c("Normalized Gini Coeff. (Train)"      = benchmark_lgb_train_ngini,
  "Normalized Gini Coeff. (Valid 5fCV)" = benchmark_lgb_valid_ngini,
  "Normalized Gini Coeff. (Test)"       = benchmark_lgb_test_ngini)
```

Le benchmark est ainsi placé. Il faudra espérer faire mieux.