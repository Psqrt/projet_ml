---
title: "Benchmark"
date: "Étape 1"
output:
  rmdformats::readthedown:
    highlight: kate
---

Le benchmark servira de seuil objectif à dépasser avec le traitement statistique de la base de données. On se servira d'un XGBM et d'un LGBM. Ce benchmark servira également à identifier les variables importantes (selon la métrique du `Gain`). La métrique qu'on souhaite optimiser est celle du `coefficient normalisé de Gini`.

Le coefficient de Gini est tel que :
$$ \text{Gini} \in \left[ 0, \frac{1 - \text{frac_pos}}{2} \right]$$
Plutôt que d'avoir une borne supérieure variable, on peut normaliser ce coefficient de façon à ce que :
$$ \text{Normalized Gini} \in [0, 1]$$

Le coefficient de Gini est lié à l'aire sous la courbe ROC (AUC). Ainsi, chercher à optimiser le coefficient de Gini (normalisé ou non) revient à optimiser l'AUC.



```{r knitr_init, echo=FALSE, cache=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
               cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA)
opts_knit$set(width=75)
```

# Importation des packages et fonctions externes

```{r, message=F, warning=F}
source("./0_packages.R")
select = dplyr::select
```

# Importation des données brutes

```{r, warning=F, message=F}
df_train = fread(file = "./../data/Base_train.csv") %>% as.data.frame()
df_test  = fread(file = "./../data/Base_test.csv")  %>% as.data.frame()
```

# Préparation des bases pour la modélisation

* XGBM a besoin d'être alimenté par un df des régresseurs (`train_X`) et d'un vecteur de réponses en facteurs (`train_Y`). Les labels à prédire ne doivent pas commencer par un chiffre (pour des soucis de restrictions de noms de colonnes). On recode `0` par `no` et `1` par `yes`.
* LGBM a besoin d'être alimenté par un objet de type `lgb.Dataset` contenant les régresseurs et les réponses (`train_XY_lgb`). Les régresseurs comme les réponses doivent être en format numérique, la fonction `lgb.prepare` s'occupe de la conversion.
* Le calcul du coefficient de Gini normalisé doit se faire avec des valeurs numériques, d'où `train_Y_num` et `test_Y_num`.
* Les df `train_id` et `test_id` conservent les identifiants au cas où.
* Une phase de gestion de mémoire termine la préparation des données pour éviter la saturation de la mémoire vive pendant le tuning des modèles.

```{r}
# XGBM
train_id        = df_train %>% select(id)
train_X         = df_train %>% select(-target, -id)
train_Y         = factor(df_train$target)
levels(train_Y) = c("no", "yes")
train_Y_num     = df_train$target # servira à calculer le coefficient de Gini

test_id         = df_test %>% select(id)
test_X          = df_test %>% select(-target, -id)
test_Y          = factor(df_test$target)
levels(test_Y)  = c("no", "yes")
test_Y_num      = df_test$target # servira à calculer le coefficient de Gini

# LGBM
train_X_lgb  = as.matrix(lgb.prepare(train_X))
train_Y_lgb  = as.matrix(lgb.prepare(df_train %>% select(target)))

test_X_lgb   = as.matrix(lgb.prepare(test_X))
test_Y_lgb   = as.matrix(lgb.prepare(df_test %>% select(target)))

train_XY_lgb = lgb.Dataset(train_X_lgb, label = train_Y_lgb)

# Gestion mémoire -- suppression des bases initiales puis garbage collection.
rm(df_train)
rm(df_test)
gc()
```

# Benchmark 1 - XGBM

## Overview

Quels paramètres sont à régler pour optimiser le modèle ?

```{r}
modelLookup("xgbTree")
```

## Tuning

La validation passe par un 5-folds cross validation. Pas plus, pas moins pour des raisons de mémoire disponible et de temps de calcul.

```{r}
tune_control <- trainControl(method          = "cv",        # validation method
                             number          = 5,           # number of CV folds
                             summaryFunction = giniSummary, # summary for evaluation
                             classProbs      = T,           # compute probabilities
                             savePredictions = T,           # keep predictions in object
                             verboseIter     = T            # enable verbose
)

tune_grid = expand.grid(
  nrounds          = seq(50, 300, 50), # number of boosting iterations
  eta              = c(0.05, 0.1),     # shrinkage rate
  max_depth        = c(4, 5, 6),       # max tree depth
  gamma            = 0,                # minimum loss reduction
  colsample_bytree = 0.7,              # subsample ratio of columns
  min_child_weight = 0,                # minimum sum of instance weight
  subsample        = 0.8               # subsample percentage
)
```

## Cross Validation and Final Model

La métrique objective est le coefficient normalisé de Gini.

```{r, eval = F}
set.seed(1234)
registerDoMC(cores = 4)
benchmark_xgbtree_model = train(
  x         = train_X,          # training data
  y         = train_Y,          # training labels
  metric    = "NormalizedGini", # objective function
  trControl = tune_control,     # validation tuning
  tuneGrid  = tune_grid,        # hyperparameters tuning
  method    = "xgbTree",        # algorithm used
)
registerDoMC(cores = 1)
```

```{r}
# save(benchmark_xgbtree_model, file = "./../data/benchmark_xgbtree_model.RData")
load("./../data/benchmark_xgbtree_model.RData")
```

## Tuning results

```{r}
ggplot(benchmark_xgbtree_model)
```

## Variable importance

```{r}
# fun_imp_ggplot_split(benchmark_xgbtree_model)
fun_imp_ggplot_split_boosting(benchmark_xgbtree_model$finalModel, "Gain")
```

## Prediction and Evaluation

```{r}
benchmark_xgbtree_train_preds      = predict(benchmark_xgbtree_model, train_X, type = "prob")
benchmark_xgbtree_test_preds       = predict(benchmark_xgbtree_model, test_X, type = "prob")
benchmark_xgbtree_train_ngini      = normalizedGini(train_Y_num, benchmark_xgbtree_train_preds[,"yes"])
benchmark_xgbtree_test_ngini       = normalizedGini(test_Y_num, benchmark_xgbtree_test_preds[,"yes"])
c("Normalized Gini Coeff. (Train)" = benchmark_xgbtree_train_ngini,
  "Normalized Gini Coeff. (Valid 5fCV)" = benchmark_xgbtree_model$results$NormalizedGini %>% max,
  "Normalized Gini Coeff. (Test)"  = benchmark_xgbtree_test_ngini)
```





# Benchmark 2 - LGBM

## Tuning

```{r}
params_lgb = list(
  objective        = "binary", # type of exercise
  metric           = "auc",    # metric to be evaluated
  learning_rate    = 0.01,     # shrinkage rate
  max_depth        = 10,       # max depth for tree model (used to deal with over-fitting when data is small)
  num_leaves       = 20,       # max number of leaves (nodes) in one tree
  is_unbalance     = T,        # is data unbalanced
  min_data_in_leaf = 10,       # min number of data in one leaf (used to deal with over-fitting)
  feature_fraction = 0.8,      # randomly select part of the features on each iteration
  bagging_fraction = 0.8,      # randomly select part of the data without resampling
  bagging_freq     = 5,        # if != 0, enables bagging, performs bagging at every k iteration
  num_threads      = 6         # number of cpu cores (not threads) to use
)
```

## Cross Validation

```{r, eval = F}
set.seed(1234)
benchmark_lgb_cv = lgb.cv(
  params                = params_lgb,         # hyperparameters
  data                  = train_XY_lgb,       # lgb.Dataset object for training
  eval                  = lgb.normalizedgini, # custom metric, additionnal to first metric
  nrounds               = 1000,               # maximum iterations
  early_stopping_rounds = 50,                 # if metric evaluation doesn't increase
  verbose               = 1,                  # enable verbose
  eval_freq             = 50,                 # verbose every n iterations
  nfold                 = 5                   # k-folds CV
)
```

## Final Model

```{r, eval = F}
benchmark_lgb_model <- lgb.train(
  params    = params_lgb,                 # hyperparameters
  data      = train_XY_lgb,               # lgb.Dataset object for training
  valids    = list(train = train_XY_lgb), # lgb.Dataset object for validation
  eval      = lgb.normalizedgini,         # custom metric, additionnal to first metric
  nrounds   = benchmark_lgb_cv$best_iter, # nrounds from CV
  verbose   = 1,                          # enable verbose
  eval_freq = 50                          # verbose every n iterations
)
```

Note : La construction du modèle LGBM s'est faite avec du calcul parallèle et pour des raisons inconnues, la sauvegarde traditionnelle par `save()` ne permet pas de réutiliser le modèle. En effet, en utilisant un `load()`, quelconque appel au modèle engendre une erreur (référence : segfault). Le package a prévu des fonctions de sauvegarde du modèle dédiées : `lgb.save()` (couplé avec `lgb.load()`).

```{r}
# lgb.save(benchmark_lgb_model, filename = "./../data/benchmark_lgb_model.txt")
# save(benchmark_lgb_cv, file = "./../data/benchmark_lgb_cv.RData")
load("./../data/benchmark_lgb_cv.RData")
benchmark_lgb_model = lgb.load("./../data/benchmark_lgb_model.txt")
```

## Variable importance

```{r}
fun_imp_ggplot_split_boosting(benchmark_lgb_model, "Gain")
```

## Prediction and Evaluation

```{r}
benchmark_lgb_train_preds          = predict(benchmark_lgb_model, train_X_lgb)
benchmark_lgb_test_preds           = predict(benchmark_lgb_model, test_X_lgb)
benchmark_lgb_train_ngini          = normalizedGini(train_Y_num, benchmark_lgb_train_preds)
benchmark_lgb_test_ngini           = normalizedGini(test_Y_num, benchmark_lgb_test_preds)
c("Normalized Gini Coeff. (Train)" = benchmark_lgb_train_ngini,
  "Normalized Gini Coeff. (Valid 5fCV)" = benchmark_lgb_cv[["record_evals"]][["valid"]][["Norm-gini"]][["eval"]] %>% unlist %>% max,
  "Normalized Gini Coeff. (Test)"  = benchmark_lgb_test_ngini)
```

# Conclusion

```{r}
print("XGBTREE/BENCHMARK")
c("Normalized Gini Coeff. (Train)" = benchmark_xgbtree_train_ngini,
  "Normalized Gini Coeff. (Valid 5fCV)" = benchmark_xgbtree_model$results$NormalizedGini %>% max,
  "Normalized Gini Coeff. (Test)"  = benchmark_xgbtree_test_ngini)

print("LGBM/BENCHMARK")
c("Normalized Gini Coeff. (Train)" = benchmark_lgb_train_ngini,
  "Normalized Gini Coeff. (Valid 5fCV)" = benchmark_lgb_cv[["record_evals"]][["valid"]][["Norm-gini"]][["eval"]] %>% unlist %>% max,
  "Normalized Gini Coeff. (Test)"  = benchmark_lgb_test_ngini)
```

Le benchmark est ainsi placé. Il faudra espérer faire mieux malgré qu'il soit relativement élevé (par rapport aux leaderboards Kaggle).