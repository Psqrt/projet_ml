---
title: "Pré-traitement"
date: "Étape 2"
output:
  rmdformats::readthedown:
    highlight: kate
---

```{r knitr_init, echo=FALSE, cache=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
               cache=TRUE,
               prompt=FALSE,
               tidy=FALSE,
               # fix pour l'erreur "Error in lazyLoadDBinsertVariable (...) long vectors not supported yet ...
               cache.lazy = FALSE, 
               comment=NA)
opts_knit$set(width=75)
```

# Importation des packages et fonctions externes

```{r, message=F, warning=F}
source("./0_packages.R")
```

# Importation des données

```{r, warning=F, message=F}
train = fread(file = "./../data/Base_train.csv") %>% as.data.frame()
test = fread(file = "./../data/Base_test.csv") %>% as.data.frame()
```

On vérifie dans un premier temps que la construction de l'échantillon test ne suit pas une logique par rapport à l'identifiant, laissant de l'information pour les modèles.

```{r}
train %>% 
  bind_rows(test, .id = "dataset") %>% 
  ggplot() +
  aes(x = id, color = dataset) +
  geom_density()
```

L'échantillonnage a été fait de façon uniforme sur les observations.




# Prétraitement des données

## Traitement des valeurs manquantes

```{r, warning=F, message=F}
# Séparation variables quanti/quali par rapport au profilage Python
# On note que `ps_car_15` prend des valeurs de racines carrés. On la retransforme pour avoir des entiers
# On transforme en integer pour optimiser l'utilisation de la mémoire vive
train = train %>% 
  mutate(ps_car_15 = as.integer(round(ps_car_15**2, 0)))

# on prend bien le soin de faire les mêmes transformations dans train et test
test = test %>% 
  mutate(ps_car_15 = as.integer(round(ps_car_15**2, 0))) 

variables = colnames(train)[2:length(colnames(train))]
variables_quanti = c("ps_reg_03", "ps_car_12", "ps_car_13", "ps_car_14", "ps_car_15")
variables_quali = variables[!(variables %in% variables_quanti)]

# fusion train/test pour les modifications simultanées mais sans contamination
# reformatage des types de variables
data = bind_rows("train" = train, "test" = test, .id = "dataset")
#     mutate_at(variables_quali, as.factor)

# liste des variables ayant des valeurs manquantes
col_na = colnames(data[colSums(is.na(data)) > 0])

# représentation des variables présentant des observations manquantes
gg_miss_var(data %>% select(dataset, col_na), 
            facet = dataset, 
            show_pct = T)
```

On note 5 variables ayant un nombre significatif de valeurs manquantes : `ps_car_03_cat`, `ps_car_05_cat`, `ps_reg_03`, `ps_car_14` et `ps_car_07_cat`. Parmi elles, trois variables sont qualitatives et deux sont quantitatives.

* La variable `ps_car_03_cat` contient trop de valeurs manquantes (en large majorité), il serait imprudent de tenter une imputation. Avant de mettre de côté cette variable, on peut vérifier le fait d'avoir une valeur manquante a une logique (information). Pour cela, on peut passer par une table de contingence, en croisant cette variable avec la `target`.

```{r}
train %>% 
  mutate(ps_car_03_cat = factor(if_else(is.na(ps_car_03_cat), -999L, ps_car_03_cat))) %>% 
  fun_crosstable("ps_car_03_cat", "target")
```

Ce tableau de contingence préconise de garder cette variable en remplaçant les valeurs manquantes par une valeur (-999). De plus, les benchmarks ont donné une grande importance à cette variable, ce qui laisse penser que les NA sont bien gérés sans imputation compliquée. Les laisser dans un groupe distinctif semble une bonne chose à faire.



* On vérifie de même pour la variable `ps_car_05_cat`.

```{r}
train %>% 
  mutate(ps_car_05_cat = if_else(is.na(ps_car_05_cat), -999L, as.integer(ps_car_05_cat))) %>% 
  fun_crosstable("ps_car_05_cat", "target")
```

On fait de même pour cette variable (pour les mêmes raisons), bien que les benchmarks n'y portent pas d'importance.



* La variable `ps_reg_03` est continue. Son grand nombre de valeurs manquantes dissuade une imputation mais il serait dommage de la supprimer, surtout si elle contient de l'information pertinente à notre problématique. On vérifie dans un premier temps si cette variable permet de discriminer la `target` à travers une différence de distribution.

```{r}
data %>% 
  filter(dataset == "train") %>% 
  ggplot() +
  aes(x = ps_reg_03, color = factor(target)) +
  geom_density()
```

De façon formelle, on peut utiliser le test de Kolmogorov-Smirnov pour vérifier si les deux échantillons sont étalés selon une même distribution.

```{r}
dgof::ks.test(train[train$target == 0, "ps_reg_03"],
              train[train$target == 1, "ps_reg_03"])
```

Le support graphique et le test de Kolmogorov-Smirnov montrent que les distributions sont différentes. On peut tester une imputation par les plus proches voisins. La valeur affectée sera alors la médiane des voisins.

Vérifions que l'absence de valeur n'ait pas une information statistique.

```{r}
train %>% 
  mutate(ps_reg_03_isna = factor(if_else(is.na(ps_reg_03), "1", "0"))) %>% 
  fun_crosstable("ps_reg_03_isna", "target")
```

Cette variable (isna) n'apporte pas d'information. Elle ne sera pas retenue et la variable initiale sera sujet à être imputée par la suite. Cette variable est bien trop importante selon les benchmarks pour être écartée.





* La variable `ps_car_14` est continue, on applique les mêmes tests que précédemment.

```{r}
data %>% 
  filter(dataset == "train") %>% 
  ggplot() +
  aes(x = ps_car_14, color = factor(target)) +
  geom_density()
```

```{r}
dgof::ks.test(train[train$target == 0, "ps_car_14"],
              train[train$target == 1, "ps_car_14"])
```

Le support graphique et le test de Kolmogorov-Smirnov montrent que les distributions sont différentes. On peut tester une imputation par les plus proches voisins. La valeur affectée sera alors la médiane des voisins.

Vérifions que l'absence de valeur n'ait pas une information statistique.

```{r}
train %>% 
  mutate(ps_car_14_isna = factor(if_else(is.na(ps_car_14), "1", "0"))) %>% 
  fun_crosstable("ps_car_14_isna", "target")
```

Cette variable (isna) n'apporte pas d'information. Elle ne sera pas retenue et la variable initiale sera sujet à être imputée par la suite. Cette variable est bien trop importante selon les benchmarks pour être écartée.


On fera de même pour toutes les autres variables à faible taux de NA : `ps_car_07_cat`, `ps_ind_05_cat`, `ps_car_09_cat`, `ps_ind_02_cat`, `ps_car_01_cat`, `ps_ind_04_cat`, `ps_car_11`, `ps_car_02_cat`, `ps_car_12`. Le faible nombre de valeurs manquantes permet d'imputer sans grande conséquence.

En conclusion à ce qui a été dit précédemment, deux variables (`ps_car_03_cat` et `ps_car_05_cat`) sont modifiées en assignant la valeur `-999` aux valeurs manquantes.

```{r}
data = data %>% 
  group_by(dataset) %>% 
  mutate(ps_car_03_cat = if_else(is.na(ps_car_03_cat), -999L, as.integer(ps_car_03_cat))) %>% 
  mutate(ps_car_05_cat = if_else(is.na(ps_car_05_cat), -999L, as.integer(ps_car_05_cat))) %>% 
  ungroup()

# liste des variables ayant des valeurs manquantes
col_na = colnames(data[colSums(is.na(data)) > 0])

# représentation des variables présentant des observations manquantes
gg_miss_var(data %>% select(dataset, col_na), 
            facet = dataset, 
            show_pct = T)
```




## Imputation

Dans un premier temps, on impute des valeurs en utilisant des forêts aléatoires (qui permettent de prendre en compte des cibles continues ou catégorielles). La variable à imputer joue le rôle de variable à expliquer tandis que les autres variables sont les régresseurs. Pour chaque variable à traiter, on retire les métadonnées (dataset et id) et la variable cible (qui est supposée inconnue pour l'échantillon test). De plus, on retire certaines variables qui posent un problème d'asymétrie d'information (les lignes nécessitant une imputation ont des modalités de variables catégorielles qui n'existent pas dans l'échantillon sans valeurs manquantes ayant servi à régresser le modèle).

**Note** : Les NA de `ps_car_14` sont parfaitement couplés avec la modalité `80` de `ps_car_11_cat`. Idem pour 25.


```{r}
# reformatage des types de variables pour éviter des valeurs impossibles (float alors qu'il s'agit d'un integer par exemple)
data = data %>% mutate_at(variables_quali, as.factor)
data_imp = data

set.seed(1234)
for (var_cible in col_na){
  print(var_cible)
  data_imp = imputation_rf(data_imp, var_cible, "id")
}
```


On vérifie qu'il n'y a plus de valeurs manquantes et on trace les distributions.

```{r}
sum(is.na(data_imp))
```

```{r}
gg_df = bind_rows("initial" = data[complete.cases(data),],
                  "imputé" = data_imp,
                  .id = "étape")

liste_gg = list()
for (i in c(1:length(col_na))) {
  
  class_var = class(data_imp[[get("col_na")[i]]])    
  
  if (class_var == "factor"){
    gg = gg_df %>% 
      ggplot() +
      aes_string(x = col_na[i], fill = "étape") + 
      geom_bar(position = "dodge")
  } else {
    gg = gg_df %>% 
      ggplot() +
      aes_string(x = col_na[i], color = "étape") + 
      geom_density()
  }
  liste_gg[[i]] = gg
}

ggarrange(plotlist = liste_gg, ncol = 4, nrow = 3, common.legend = T)

rm(gg_df)
gc()
```



## Exportation

On exporte la base sans valeurs manquantes, tout en remettant les bons formats de colonnes.

```{r, eval = F}
ind_factor = grep("bin|cat", colnames(data_imp))

type_col = c(rep("numeric", ncol(data_imp)))
names(type_col) = colnames(data_imp)
type_col[ind_factor] = "factor"
type_col[1:3] = c("character", "numeric", "factor")

saveRDS(object = type_col,
        file = "./../data/data_imp_type_col.rds")
write.csv(x = data_imp,
          file = "./../data/data_imp.csv",
          quote = T,
          row.names = F)
```

