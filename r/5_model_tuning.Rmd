---
title: "Paramétrisation des modèles"
date: "Étape 5"
output:
  rmdformats::readthedown:
    highlight: kate
---

```{r knitr_init, echo=FALSE, cache=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print = "75")
opts_chunk$set(echo    = TRUE,
               prompt  = FALSE,
               tidy    = FALSE,
               comment = NA)
opts_knit$set(width = 75)
```

La liste des modèles sont au nombre de 10 : arbre de décision, régression logistique, forêt aléatoire, ada boosting, régression logistique pénalisée, k plus proches voisins, analyse discriminante linéaire, gradient boosting machine, machine à vecteurs de support, extreme gradient boosting. Il y a 4 stratégies de resampling à tester : downsampling, upsampling, smote et sans resampling. Ceci fait 40 modèles plus ou moins sophistiqués et qui prennent plus ou moins du temps à être paramétrés (par grid search). Par conséquent, l'hyperparamétrisation de ces 40 modèles se fait grâce aux possibilités offertes par kaggle.

Les codes ci-dessous servent à montrer la grille de recherche de chaque modèle. Les 40 scripts pour paramétrer les modèles sont dans le répertoire "jobs/kaggle_job". Certains modèles (les plus gourmands en temps de calcul) n'ont pas été construits à cause de la limite de 9 heures d'exécution de kaggle. Au final, 31 des 40 modèles ont été construits, avec 4 autres modèles : light gbm en upsampling et sans resampling et deux modèles de stacking.

<table style="width: 76px;">
<tbody>
<tr>
<td style="width: 15px;">&nbsp;</td>
<td style="width: 15px;">&nbsp;up</td>
<td style="width: 15px;">down</td>
<td style="width: 15px;">smote</td>
<td style="width: 15px;">none</td>
</tr>
<tr>
<td style="width: 15px;">XGB </td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">OK </td>
<td style="width: 15px;">OK</td>
</tr>
<tr>
<td style="width: 15px;">TREE</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">&nbsp;</td>
</tr>
<tr>
<td style="width: 15px;">RF</td>
<td style="width: 15px;">&nbsp;</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">OK</td>
</tr>
<tr>
<td style="width: 15px;">LDA</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">OK</td>
</tr>
<tr>
<td style="width: 15px;">GBM</td>
<td style="width: 15px;">&nbsp;</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">OK</td>
</tr>
<tr>
<td style="width: 15px;">ADA</td>
<td style="width: 15px;">&nbsp;</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">OK</td>
</tr>
<tr>
<td style="width: 15px;">NET</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">OK</td>
</tr>
<tr>
<td style="width: 15px;">SVM</td>
<td style="width: 15px;">&nbsp;</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">&nbsp;</td>
<td style="width: 15px;">&nbsp;</td>
</tr>
<tr>
<td style="width: 15px;">KPPV</td>
<td style="width: 15px;">&nbsp;</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">&nbsp;</td>
</tr>
<tr>
<td style="width: 15px;">GLM</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">OK</td>
</tr>
<tr>
<td style="width: 15px;">LGB</td>
<td style="width: 15px;">&nbsp;</td>
<td style="width: 15px;">OK</td>
<td style="width: 15px;">&nbsp;</td>
<td style="width: 15px;">OK</td>
</tr>
</tbody>
</table>
<p>&nbsp;</p>

En revanche, les objets R contenant les résultats des validations des modèles étant trop lourds, ils ne sont pas disponibles dans ce répertoire.

# Importation des Packages et fonctions externes

```{r, message=F, warning=F}
source("./0_packages.R")

# library(doMC)
# registerDoMC(cores = 8)
```

# Importation des données

```{r}
load("./../data/bases_35features.RData")

# Prépration des données pour les modèles
train_id = train$id
train_X  = train %>% select(-id, -target)
train_Y  = train$target
train_XY = train %>% select(-id)

test_id = test$id
test_X  = test %>% select(-id, -target)
test_Y  = test$target %>% as.numeric()
test_Y  = test_Y - 1
```

# Exportations

Répertoire qui contiendra les sauvegardes de modèles.

```{r}
path_exportation = file.path("/home/psqrt/Téléchargements/000")
```

# Paramètres de validation

Stratégie de validation : 5 folds CV. Tous les modèles sont testés avec du up-sampling, down-sampling, smote ou rien.

Il faut relancer la validation avec les différentes méthodes de resampling.

```{r, eval = F}
tune_control <- trainControl(method = "cv",
                             number = 5,
                             summaryFunction = giniSummary,
                             classProbs = T,
                             savePredictions = T,
                             verboseIter = T,
                             sampling = NULL) # NULL, smote, down, up
```

# Modèles

## Arbre de décision

```{r, eval = F}

set.seed(1234)
modelLookup("rpart2")

tune_grid = expand.grid(
  maxdepth = 1:5
)

tree_model = train(
  target ~ .,
  data = train_XY,
  metric = "NormalizedGini",
  trControl = tune_control,
  tuneGrid = tune_grid,
  method = "rpart2"
)

save(tree_model, file = file.path(path_exportation, "tree_model.RData"))
rm(tree_model)
gc()

```

## Régression logistique

```{r, eval = F}

set.seed(1234)
modelLookup("glm")

glm_binomial_model = train(
  target ~ .,
  data = train_XY,
  metric = "NormalizedGini",
  trControl = tune_control,
  method = "glm",
  family = "binomial"
)

save(glm_binomial_model, file = file.path(path_exportation, "glm_binomial_model.RData"))
rm(glm_binomial_model)
gc()

```

## Forêt aléatoire (ranger)

```{r, eval = F}

set.seed(1234)
modelLookup("ranger")

tune_grid = expand.grid(
  mtry = c(3:(floor((ncol(train_XY)) * 0.8))),
  splitrule = "gini",
  min.node.size = 1
)

foret_model = train(
  target ~ .,
  data = train_XY,
  metric = "NormalizedGini",
  trControl = tune_control,
  tuneGrid = tune_grid,
  method = "ranger",
  importance = "impurity"
)

save(foret_model, file = file.path(path_exportation, "foret_model.RData"))
rm(foret_model)
gc()

```

## AdaBoosting

```{r, eval = F}

set.seed(1234)
modelLookup("ada")

tune_grid = expand.grid(
  iter = 500,
  maxdepth = 5,
  nu = 0.1
)

ada_model = train(
  target ~ .,
  data = train_XY,
  metric = "NormalizedGini",
  trControl = tune_control,
  tuneGrid = tune_grid,
  method = "ada",
)

save(ada_model, file = file.path(path_exportation, "ada_model.RData"))
rm(ada_model)
gc()

```

## GLMnet

```{r, eval = F}

set.seed(1234)
modelLookup("glmnet")

tune_grid = expand.grid(
  alpha = seq(0, 1, 0.1),
  lambda = seq(0, 3, 0.2)
)

glmnet_model = train(
  target ~ .,
  data = train_XY,
  metric = "NormalizedGini",
  trControl = tune_control,
  tuneGrid = tune_grid,
  method = "glmnet",
)

save(glmnet_model, file = file.path(path_exportation, "glmnet_model.RData"))
rm(glmnet_model)
gc()

```

## KNN

```{r, eval = F}

set.seed(1234)
modelLookup("knn")

tune_grid = expand.grid(
  k = 3
)

kppv_model = train(
  target ~ .,
  data = train_XY,
  metric = "NormalizedGini",
  trControl = tune_control,
  tuneGrid = tune_grid,
  method = "knn",
)

save(kppv_model, file = file.path(path_exportation, "kppv_model.RData"))
rm(kppv_model)
gc()

```


## LDA

```{r, eval = F}

set.seed(1234)
modelLookup("lda")

lda_model = train(
  target ~ .,
  data = train_XY,
  metric = "NormalizedGini",
  trControl = tune_control,
  method = "lda",
)


save(lda_model, file = file.path(path_exportation, "lda_model.RData"))
rm(lda_model)
gc()

```

## GBM

```{r, eval = F}

set.seed(1234)
modelLookup("gbm")

tune_grid = expand.grid(
  n.trees = seq(300, 600, 100),
  interaction.depth = seq(1, 6, 1),
  shrinkage = 0.1,
  n.minobsinnode = 1
)

gbm_model = train(
  target ~ .,
  data = train_XY,
  metric = "NormalizedGini",
  trControl = tune_control,
  tuneGrid = tune_grid,
  method = "gbm"
)

save(gbm_model, file = file.path(path_exportation, "gbm_model.RData"))
rm(gbm_model)
gc()

```


## SVM (radial kernel)

```{r, eval = F}

set.seed(1234)
modelLookup("svmRadial")

tune_grid = expand.grid(
  sigma = 1,
  C = 1
)

svm_model = train(
  target ~ .,
  data = train_XY,
  metric = "NormalizedGini",
  trControl = tune_control,
  tuneGrid = tune_grid,
  method = "svmRadial",
)

save(svm_model, file = file.path(path_exportation, "svm_model.RData"))
rm(svm_model)
gc()

```

## XGB

```{r, eval = F}

set.seed(1234)
modelLookup("xgbTree")

tune_grid = expand.grid(
  nrounds = seq(100, 500, 100),
  eta = c(0.05, 0.1),
  max_depth = c(4, 5, 6),
  gamma = 0,
  colsample_bytree = 0.7,
  min_child_weight = 0,
  subsample = 0.7
)

xgbtree_model = train(
  target ~ .,
  data = train_XY,
  metric = "NormalizedGini",
  trControl = tune_control,
  tuneGrid = tune_grid,
  method = "xgbTree",
)

save(xgbtree_model, file = file.path(path_exportation, "xgbtree_model.RData"))
rm(xgbtree_model)
gc()

```

## LGBM

Tuning du LGBM en up-sampling et sans resampling.

Préparation des données :

```{r}
# Préparation des données pour le LGBM
train_X_lgb  = train %>% 
  select(-id, -target) %>% 
  lgb.prepare() %>% 
  as.matrix()

train_Y_lgb = train %>% 
  select(target) %>% 
  lgb.prepare() %>% 
  as.matrix() - 1

train_Y_num = as.numeric(train$target) - 1

test_X_lgb   = test %>% 
  select(-id, -target) %>% 
  lgb.prepare() %>% 
  as.matrix() 

test_Y_lgb = test %>% 
  select(target) %>% 
  lgb.prepare() %>% 
  as.matrix()

test_Y_num = as.numeric(test$target) - 1

train_XY_lgb = lgb.Dataset(train_X_lgb, label = train_Y_lgb)
```

### Up-sampling

On grid-search pour optimiser les paramètres :

```{r, eval = F}
up_lgb_tune_df = data.frame(
  "max_depth"        = numeric(),
  "num_leaves"       = numeric(),
  "feature_fraction" = numeric(),
  "bagging_fraction" = numeric(),
  "iteration"        = numeric(),
  "validation"       = numeric()
)

for (max_depth_param in c(5, 10, 15)){
  for (num_leaves_param in c(10, 15, 20, 25)) {
    for (feature_fraction_param in c(0.7, 0.8, 0.9)) {
      for (bagging_fraction_param in c(0.6, 0.7, 0.8)) {
        
        set.seed(1234)
        params_lgb = list(
          objective        = "binary",               # type of exercise
          metric           = "auc",                  # metric to be evaluated
          learning_rate    = 0.01,                   # shrinkage rate
          max_depth        = max_depth_param,        # max depth for tree model (used to deal with over-fitting)
          num_leaves       = num_leaves_param,       # max number of leaves (nodes) in one tree
          scale_pos_weight = 26,                     # weight positive class
          min_data_in_leaf = 1,                      # min number of data in one leaf (used to deal with over-fitting)
          feature_fraction = feature_fraction_param, # randomly select part of the features per iteration
          bagging_fraction = bagging_fraction_param, # randomly select part of the data without resampling
          bagging_freq     = 5,                      # if != 0, enables bagging, performs bagging at every k iteration
          num_threads      = 6                       # number of cpu cores (not threads) to use
        )
        
        up_lgb_cv = lgb.cv(
          params                = params_lgb,         # hyperparameters
          data                  = train_XY_lgb,       # lgb.Dataset object for training
          eval                  = lgb.normalizedgini, # custom metric, additionnal to first metric
          nrounds               = 1000,               # maximum iterations
          early_stopping_rounds = 50,                 # if metric evaluation doesn't increase
          verbose               = 1,                  # enable verbose
          eval_freq             = 50,                 # verbose every n iterations
          nfold                 = 5                   # k-folds CV
        )
        
        row_param = data.frame(
          "max_depth"        = max_depth_param,
          "num_leaves"       = num_leaves_param,
          "feature_fraction" = feature_fraction_param,
          "bagging_fraction" = bagging_fraction_param,
          "iteration"        = up_lgb_cv$best_iter,
          "validation"       = max(unlist(up_lgb_cv[["record_evals"]][["valid"]][["Norm-gini"]][["eval"]]))
        )
        up_lgb_tune_df = up_lgb_tune_df %>% bind_rows(row_param)
        
      }
    }
  }
}
```

```{r}
# save(up_lgb_tune_df, file = "./../data/up_lgb_tune_df.RData")
load("./../data/up_lgb_tune_df.RData")

up_lgb_best_tune = up_lgb_tune_df %>% 
  arrange(-validation) %>% 
  slice(1)
```

On a trouvé les bonnes valeurs de paramètres, on construit le modèle pour avoir le Gini sur train et test (le score sur test n'est pas à tenir compte car il est censé être inconnu jusqu'à la fin).

```{r, eval = F}
set.seed(1234)
params_lgb = list(
  objective        = "binary",                            # type of exercise
  metric           = "auc",                               # metric to be evaluated
  learning_rate    = 0.01,                                # shrinkage rate
  max_depth        = up_lgb_best_tune$max_depth,          # max depth for tree model (used to deal with over-fitting when data is small)
  num_leaves       = up_lgb_best_tune$num_leaves,         # max number of leaves (nodes) in one tree
  scale_pos_weight = 26,                                  # weght positive class
  min_data_in_leaf = 1,                                   # min number of data in one leaf (used to deal with over-fitting)
  feature_fraction = up_lgb_best_tune$feature_fraction,   # randomly select part of the features on each iteration
  bagging_fraction = up_lgb_best_tune$bagging_fraction,   # randomly select part of the data without resampling
  bagging_freq     = 5,                                   # if != 0, enables bagging, performs bagging at every k iteration
  num_threads      = 6                                    # number of cpu cores (not threads) to use
)

up_lgb_model <- lgb.train(
  params    = params_lgb,                        # hyperparameters
  data      = train_XY_lgb,                      # lgb.Dataset object for training
  valids    = list(train = train_XY_lgb),        # lgb.Dataset object for validation
  eval      = lgb.normalizedgini,                # custom metric, additionnal to first metric
  nrounds   = up_lgb_best_tune$iteration,        # nrounds from CV
  verbose   = 1,                                 # enable verbose
  eval_freq = 50                                 # verbose every n iterations
)
```

```{r}
# save(up_lgb_cv, file = "./../data/up_lgb_cv.RData")
# lgb.save(up_lgb_model, filename = "./../data/up_lgb_model.txt")
load("./../data/up_lgb_cv.RData")
up_lgb_model = lgb.load("./../data/up_lgb_model.txt")
```

```{r}
# Les prédictions pour le LGB se font ici pour y récupérer les performances et éviter de devoir le faire dans le RMD7
up_lgb_train_preds          = predict(up_lgb_model, train_X_lgb)
up_lgb_test_preds           = predict(up_lgb_model, test_X_lgb)
up_lgb_train_ngini          = normalizedGini(train_Y_num, up_lgb_train_preds)
up_lgb_test_ngini           = normalizedGini(test_Y_num, up_lgb_test_preds)
up_lgb_valid_ngini          = max(unlist(up_lgb_cv[["record_evals"]][["valid"]][["Norm-gini"]][["eval"]]))
c("Normalized Gini Coeff. (Train)"        = up_lgb_train_ngini,
  "Normalized Gini Coeff. (Valid - 5fCV)" = up_lgb_valid_ngini,
  "Normalized Gini Coeff. (Test)"         = up_lgb_test_ngini)
up_lgb_info = data.frame("Method"     = "lgb",
                         "Sampling"   = "up",
                         "Train"      = up_lgb_train_ngini,
                         "Validation" = up_lgb_valid_ngini,
                         "Test"       = up_lgb_test_ngini,
                         stringsAsFactors = F)

# save(up_lgb_info, file = "./../data/up_lgb_info.RData")
```

On sauvegarde les scores pour plus tard.

### None

On fait pareil mais sans resampling

```{r, eval = F}
none_lgb_tune_df = data.frame(
  "max_depth"        = numeric(),
  "num_leaves"       = numeric(),
  "feature_fraction" = numeric(),
  "bagging_fraction" = numeric(),
  "iteration"        = numeric(),
  "validation"       = numeric()
)

for (max_depth_param in c(5, 10, 15)){
  for (num_leaves_param in c(15, 20, 25)) {
    for (feature_fraction_param in c(0.7, 0.8)) {
      for (bagging_fraction_param in c(0.7, 0.8)) {
        
        set.seed(1234)
        params_lgb = list(
          objective        = "binary",               # type of exercise
          metric           = "auc",                  # metric to be evaluated
          learning_rate    = 0.01,                   # shrinkage rate
          max_depth        = max_depth_param,        # max depth for tree model (used to deal with over-fitting)
          num_leaves       = num_leaves_param,       # max number of leaves (nodes) in one tree
          is_unbalance     = T,                      # is data unbalanced (disable this if using scale_pos_weight)
          min_data_in_leaf = 1,                      # min number of data in one leaf (used to deal with over-fitting)
          feature_fraction = feature_fraction_param, # randomly select part of the features per iteration
          bagging_fraction = bagging_fraction_param, # randomly select part of the data without resampling
          bagging_freq     = 5,                      # if != 0, enables bagging, performs bagging at every k iteration
          num_threads      = 6                       # number of cpu cores (not threads) to use
        )
        
        none_lgb_cv = lgb.cv(
          params                = params_lgb,         # hyperparameters
          data                  = train_XY_lgb,       # lgb.Dataset object for training
          eval                  = lgb.normalizedgini, # custom metric, additionnal to first metric
          nrounds               = 1000,               # maximum iterations
          early_stopping_rounds = 50,                 # if metric evaluation doesn't increase
          verbose               = 1,                  # enable verbose
          eval_freq             = 50,                 # verbose every n iterations
          nfold                 = 5                   # k-folds CV
        )
        
        row_param = data.frame(
          "max_depth"        = max_depth_param,
          "num_leaves"       = num_leaves_param,
          "feature_fraction" = feature_fraction_param,
          "bagging_fraction" = bagging_fraction_param,
          "iteration"        = none_lgb_cv$best_iter,
          "validation"       = max(unlist(none_lgb_cv[["record_evals"]][["valid"]][["Norm-gini"]][["eval"]]))
        )
        none_lgb_tune_df = none_lgb_tune_df %>% bind_rows(row_param)
        
      }
    }
  }
}
```

```{r}
# save(none_lgb_tune_df, file = "./../data/none_lgb_tune_df.RData")
load("./../data/none_lgb_tune_df.RData")

none_lgb_best_tune = none_lgb_tune_df %>% 
  arrange(-validation) %>% 
  slice(1)
```

```{r, eval = F}
set.seed(1234)
params_lgb = list(
  objective        = "binary",                            # type of exercise
  metric           = "auc",                               # metric to be evaluated
  learning_rate    = 0.01,                                # shrinkage rate
  max_depth        = none_lgb_best_tune$max_depth,        # max depth for tree model (used to deal with over-fitting when data is small)
  num_leaves       = none_lgb_best_tune$num_leaves,       # max number of leaves (nodes) in one tree
  is_unbalance     = T,                                   # is data unbalanced (disable this if using scale_pos_weight)
  min_data_in_leaf = 1,                                   # min number of data in one leaf (used to deal with over-fitting)
  feature_fraction = none_lgb_best_tune$feature_fraction, # randomly select part of the features on each iteration
  bagging_fraction = none_lgb_best_tune$bagging_fraction, # randomly select part of the data without resampling
  bagging_freq     = 5,                                   # if != 0, enables bagging, performs bagging at every k iteration
  num_threads      = 6                                    # number of cpu cores (not threads) to use
)

none_lgb_model <- lgb.train(
  params    = params_lgb,                        # hyperparameters
  data      = train_XY_lgb,                      # lgb.Dataset object for training
  valids    = list(train = train_XY_lgb),        # lgb.Dataset object for validation
  eval      = lgb.normalizedgini,                # custom metric, additionnal to first metric
  nrounds   = none_lgb_best_tune$iteration,      # nrounds from CV
  verbose   = 1,                                 # enable verbose
  eval_freq = 50                                 # verbose every n iterations
)
```

```{r}
# save(none_lgb_cv, file = "./../data/none_lgb_cv.RData")
# lgb.save(none_lgb_model, filename = "./../data/none_lgb_model.txt")
load("./../data/none_lgb_cv.RData")
none_lgb_model = lgb.load("./../data/none_lgb_model.txt")
```

```{r}
none_lgb_train_preds          = predict(none_lgb_model, train_X_lgb)
none_lgb_test_preds           = predict(none_lgb_model, test_X_lgb)
none_lgb_train_ngini          = normalizedGini(train_Y_num, none_lgb_train_preds)
none_lgb_test_ngini           = normalizedGini(test_Y_num, none_lgb_test_preds)
none_lgb_valid_ngini          = max(unlist(none_lgb_cv[["record_evals"]][["valid"]][["Norm-gini"]][["eval"]]))
c("Normalized Gini Coeff. (Train)"        = none_lgb_train_ngini,
  "Normalized Gini Coeff. (Valid - 5fCV)" = none_lgb_valid_ngini,
  "Normalized Gini Coeff. (Test)"         = none_lgb_test_ngini)
none_lgb_info = data.frame("Method"     = "lgb",
                           "Sampling"   = "none",
                           "Train"      = none_lgb_train_ngini,
                           "Validation" = none_lgb_valid_ngini,
                           "Test"       = none_lgb_test_ngini,
                           stringsAsFactors = F)

# save(none_lgb_info, file = "./../data/none_lgb_info.RData")
```

## Stacking

Après avoir comparé les performances de modèle (Rmd n°6), on tente un stacking de deux modèles : LGB et XGB sans resampling.

```{r}
none_lgb_model = lgb.load(file.path(path_exportation, "none_lgb_model.txt"))
load(file.path(path_exportation, "none_xgbtree_model.RData"))
```

### Stacking par GLM

L'objet lgb.cv ne contenant pas les prédictions CV de la meilleur itération (959ème) mais uniquement la dernière (1000ème), on relance le LGB avec les paramètres tunés et la meilleure itération comme dernière itération à faire. La dernière itération sera donc la meilleure itération.

```{r, eval = F}
set.seed(1234)
params_lgb = list(
  objective        = "binary",                            # type of exercise
  metric           = "auc",                               # metric to be evaluated
  learning_rate    = 0.01,                                # shrinkage rate
  max_depth        = none_lgb_best_tune$max_depth,        # max depth for tree model (used to deal with over-fitting)
  num_leaves       = none_lgb_best_tune$num_leaves,       # max number of leaves (nodes) in one tree
  is_unbalance     = T,                                   # is data unbalanced (disable this if using scale_pos_weight)
  min_data_in_leaf = 1,                                   # min number of data in one leaf (used to deal with over-fitting)
  feature_fraction = none_lgb_best_tune$feature_fraction, # randomly select part of the features per iteration
  bagging_fraction = none_lgb_best_tune$bagging_fraction, # randomly select part of the data without resampling
  bagging_freq     = 5,                                   # if != 0, enables bagging, performs bagging at every k iteration
  num_threads      = 6                                    # number of cpu cores (not threads) to use
)

none_lgb_cv_stacking = lgb.cv(
  params                = params_lgb,         # hyperparameters
  data                  = train_XY_lgb,       # lgb.Dataset object for training
  eval                  = lgb.normalizedgini, # custom metric, additionnal to first metric
  nrounds               = 959,                # maximum iterations (obtenir 959 en itérant jusqu'à 1000 puis placer la bonne valeur)
  early_stopping_rounds = 50,                 # if metric evaluation doesn't increase
  verbose               = 1,                  # enable verbose
  eval_freq             = 50,                 # verbose every n iterations
  nfold                 = 5                   # k-folds CV
)
```

```{r}
# save(none_lgb_cv_stacking, file = "./../data/none_lgb_cv_stacking.RData")
load("./../data/none_lgb_cv_stacking.RData")
```


On récupère les prédictions CV.

Source pour la fonction d'extraction des prédictions : https://github.com/Microsoft/LightGBM/issues/283

```{r}
none_lgb_cv_stacking_valid_preds = get_lgbm_cv_preds(none_lgb_cv_stacking)

# on enregistre les prédictions pour la courbe roc plus tard
# save(none_lgb_cv_stacking_valid_preds, file = "./../data/none_lgb_stacking_valid_preds.RData")
```

L'extraction des prédictions CV est plus simple pour le XGB, car déjà stockées et facilement accessibles.

```{r}
none_xgb_cv_stacking_valid_preds = none_xgbtree_model$pred %>% 
  filter(max_depth == none_xgbtree_model$bestTune$max_depth) %>% 
  filter(nrounds == none_xgbtree_model$bestTune$nrounds) %>% 
  filter(eta == none_xgbtree_model$bestTune$eta) %>% 
  arrange(rowIndex) %>% 
  select(yes)
```

Les deux listes de prédictions sont ordonnées selon l'index de la ligne dans la base d'apprentissage, donc on peut les concaténer dans un data.frame tout simplement.

```{r}
df_stacking_train = data.frame("id"          = train_id,
                               "target"      = factor(train_Y, labels = c("no", "yes")),
                               "lgb_learner" = none_lgb_cv_stacking_valid_preds,
                               "xgb_learner" = none_xgb_cv_stacking_valid_preds$yes)

df_stacking_train_X = df_stacking_train %>% 
  select(-id, -target)
```

On lance le méta-classifieur qui est une régression logistique. Validation croisée 5 blocs comme depuis le départ.

```{r}
tune_control <- trainControl(method          = "cv",
                             number          = 5,
                             summaryFunction = giniSummary,
                             classProbs      = T,
                             savePredictions = T,
                             verboseIter     = T,
                             sampling        = NULL) # NULL, smote, down, up

set.seed(1234)
modelLookup("glm")

glm_stacking_model = train(
  target ~ . - id,
  data      = df_stacking_train,
  metric    = "NormalizedGini",
  trControl = tune_control,
  method    = "glm",
  family    = "binomial"
)
```

```{r}
none_stacking_train_preds  = predict(glm_stacking_model$finalModel, df_stacking_train_X, type = "response")
none_stacking_train_ngini  = normalizedGini(train_Y_num, none_stacking_train_preds)
none_stacking_valid_ngini  = max(glm_stacking_model$results$NormalizedGini)
c("Train" = none_stacking_train_ngini,
  "Valid" = none_stacking_valid_ngini,
  "Test" = NA)

glm_stacking_model_info = data.frame("Method"     = "glm_stack",
                                     "Sampling"   = "none",
                                     "Train"      = none_stacking_train_ngini,
                                     "Validation" = none_stacking_valid_ngini,
                                     "Test"       = NA,
                                     stringsAsFactors = F)

# on extrait les prédictions pour la courbe roc plus tard
none_glm_stacking_valid_preds = glm_stacking_model$pred %>% 
  arrange(rowIndex) %>% 
  .$yes
```

```{r}
# save(glm_stacking_model_info, file = "./../data/glm_stacking_model_info.RData")
# save(none_glm_stacking_valid_preds, file = "./../data/none_glm_stacking_valid_preds.RData")
```


Le score de validation est le meilleur par rapport aux autres modèles.

### Stacking avec combinaison linéaire (combinaison)

```{r}
df_results_valid_combinaison = data.frame("alpha" = seq(0, 1, 0.01),
                                          "validation" = numeric(length(seq(0, 1, 0.01))))

df_combinaison_train = df_stacking_train %>% 
  mutate(target_num = as.numeric(target) - 1)
for (alpha in seq(0, 1, 0.01)) {
  dvalid = df_combinaison_train %>% 
    mutate(pred_combinaison = alpha * lgb_learner + (1 - alpha) * xgb_learner)
  gini_alpha = normalizedGini(dvalid$target_num, dvalid$pred_combinaison)
  df_results_valid_combinaison[which(df_results_valid_combinaison$alpha == alpha), "validation"] = gini_alpha
}
```

```{r}
df_results_valid_combinaison %>% 
  ggplot() +
  aes(x = alpha, y = validation) +
  annotate(geom = "text", x = 0.08, y = 0.2776, label = "100% XGB") +
  annotate(geom = "text", x = 0.97, y = 0.277, label = "100% LGB") +
  geom_point()
```

```{r}
best_tune_combinaison = df_results_valid_combinaison %>% 
  arrange(-validation) %>% 
  slice(1)

best_tune_combinaison
```

Score meilleur à nouveau.

Ça donne quoi sur test ?

- récupérer les predictions LGB sur test
- récupérer les prédictions XGB sur test
- faire la combinaison linéaire
- tester le score

```{r}
none_lgb_train_preds = predict(none_lgb_model, train_X_lgb, type = "prob")
none_xgb_train_preds = predict(none_xgbtree_model, train_X, type = "prob")[, "yes"]

none_lgb_test_preds = predict(none_lgb_model, test_X_lgb, type = "prob")
none_xgb_test_preds = predict(none_xgbtree_model, test_X, type = "prob")[, "yes"]

none_combi_valid_preds = best_tune_combinaison$alpha * none_lgb_cv_stacking_valid_preds + (1 - best_tune_combinaison$alpha) * none_xgb_cv_stacking_valid_preds$yes

# save(none_combi_valid_preds, file = "./../data/none_combi_valid_preds.RData")

df_train_stacking = data.frame("id"          = train_id,
                               "target"      = factor(train_Y, labels = c("no", "yes")),
                               "lgb_learner" = none_lgb_train_preds,
                               "xgb_learner" = none_xgb_train_preds)

df_test_stacking = data.frame("id"          = test_id,
                              "target"      = factor(test_Y, labels = c("no", "yes")),
                              "lgb_learner" = none_lgb_test_preds,
                              "xgb_learner" = none_xgb_test_preds)

df_train_combi = df_train_stacking %>% 
  mutate(combinaison = best_tune_combinaison$alpha * lgb_learner + (1 - best_tune_combinaison$alpha) * xgb_learner)

df_test_combi = df_test_stacking %>% 
  mutate(combinaison = best_tune_combinaison$alpha * lgb_learner + (1 - best_tune_combinaison$alpha) * xgb_learner)

# save(df_test_combi, file = "./../data/none_combi_test_preds.RData")

none_combi_train_ngini = normalizedGini(train_Y_num, df_train_combi$combinaison)
none_combi_test_ngini  = normalizedGini(test_Y_num, df_test_combi$combinaison)

# pour information (comparer avec les autres)
auc(test_Y_num, df_test_combi$combinaison)

combinaison_model_info = data.frame("Method"     = "combi",
                                    "Sampling"   = "none",
                                    "Train"      = none_combi_train_ngini,
                                    "Validation" = best_tune_combinaison$validation,
                                    "Test"       = none_combi_test_ngini,
                                    stringsAsFactors = F)

combinaison_model_info
```

```{r}
# save(combinaison_model_info, file = "./../data/combinaison_model_info.RData")
```
