Données déséquilibrées => algorithmes non performants :
	- rééquilibrage par échantillonnage (autant de 1 et de 0 : plus de 30%)
		- varier les poids selon le groupe (par défaut 1/N_{app}) : on peut avoir un ratio 30:1 puis renormaliser.
		- rééchantillonnage : on tire au hasard avec remise 80% parmis les 1 et on complète avec 0.8 x N_1 tirés parmis les 0 (sous-échantillonnage du groupe majoritaire : 0).
		Sinon on tire 80% parmis les 0 et on suréchantillonne les 1.
		- faire un clustering avec beaucoup de classes et on tire dans les classes (ou centres de classes).
		- SMOTE : tirer avec remise le groupe minoritaire puis interpoler pour construire des individus fictifs.
		
L'ensemble de test doit être proche de la réalité (donc la base de test doit être déséquilibrée).

Les transformations de données doivent être faites sur chaque base mais doivent être identiques. Par exemple, si on retranche la moyenne issue du jeu d'apprentissage sur le jeu d'apprentissage, il faut retrancher cette même moyenne sur le jeu de test.

Pour les différentes méthodes de rééquilibrage, on peut comparer les différentes approches avec des moyennes et écart-types / boxplots (observations : performances des modèles).

ACM pour identifier les modalités à rassembler
Traitement sur données initiales puis rééchantillonnage
Régression logistique pénalisée : cross validation pour choisir le poids de la pénalisation

Rééchantillonnage > Ajuster forêt aléatoire > Identifier les variables non importantes pour les jetter directement pour ne pas perdre du temps dessus.

Gestion NA
	- supprimer les variables avec un fort ratio NA
			- vérifier que la dépendance n'est pas trop élevée avec la target
	- supprimer les individus
			- s'assurer qu'ils n'appartiennent pas trop de target = 1
	- imputation par knn, acp
	
Construire des fonctions pour extraire toutes les performances des modèles de façon automatique
Réfléchir à la méthode de validation